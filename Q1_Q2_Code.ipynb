{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "\n",
        "device = cuda.Device(0)\n",
        "print('S20200010072, S20200010047')\n",
        "print('\\n')\n",
        "print(\"Device name: \", device.name())\n",
        "print(\"Warp size: \", device.warp_size)\n",
        "print(\"Compute capability: \", \"%d.%d\" % device.compute_capability())\n",
        "print(\"Max GPU memory size: \", device.total_memory())\n",
        "print(\"Max block dimensions: \", device.max_block_dim_x, device.max_block_dim_y, device.max_block_dim_z)\n",
        "print(\"Max grid dimensions: \", device.max_grid_dim_x, device.max_grid_dim_y, device.max_grid_dim_z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EWx81wePjjq",
        "outputId": "2c695260-0727-43da-accd-5fc8a457a376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.9/dist-packages (2022.2.2)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.2.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.9/dist-packages (from pycuda) (2022.1.14)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
            "S20200010072, S20200010047\n",
            "\n",
            "\n",
            "Device name:  Tesla T4\n",
            "Warp size:  32\n",
            "Compute capability:  7.5\n",
            "Max GPU memory size:  15835398144\n",
            "Max block dimensions:  1024 1024 64\n",
            "Max grid dimensions:  2147483647 65535 65535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztx7Jc9rNJV3",
        "outputId": "3196be28-5ab6-4326-dc80-d2951de96c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S20200010072,S20200010047\n",
            "Enter T Value: 256\n",
            "Enter B Value: 128\n",
            "Time taken is\n",
            "T: 256, B: 128, N: 1000000, Time: 0.236923s\n",
            "\n",
            "\n",
            "T: 256, B: 128, N: 1000000, Time: 0.000129s\n",
            "T: 512, B: 64, N: 1000000, Time: 0.000686s\n",
            "T: 1024, B: 32, N: 1000000, Time: 0.000469s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.9/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "import time\n",
        "\n",
        "@cuda.jit\n",
        "def prefixSum(data):\n",
        "    tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    if tid >= data.shape[0]:\n",
        "        return\n",
        "\n",
        "    for stride in range(1, cuda.blockDim.x):\n",
        "        index = 2 * stride * (tid + 1) - 1\n",
        "        if index < data.shape[0]:\n",
        "            data[index] += data[index - stride]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "    for stride in range(cuda.blockDim.x // 2, 0, -1):\n",
        "        cuda.syncthreads()\n",
        "        index = 2 * stride * (tid + 1) - 1\n",
        "        if index + stride < data.shape[0]:\n",
        "            data[index + stride] += data[index]\n",
        "\n",
        "def runPrefixSum(T, B, N):\n",
        "    data = np.random.rand(N).astype(np.float32)\n",
        "\n",
        "    d_data = cuda.to_device(data)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    prefixSum[B, T](d_data)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    h_data = d_data.copy_to_host()\n",
        "\n",
        "    print(\"T: {}, B: {}, N: {}, Time: {:.6f}s\".format(T, B, N, end - start))\n",
        "\n",
        "\n",
        "print('S20200010072,S20200010047')\n",
        "T = int(input('Enter T Value: '))\n",
        "B = int(input('Enter B Value: '))\n",
        "N = 1000000\n",
        "print('Time taken is')\n",
        "runPrefixSum(T,B,N)\n",
        "print('\\n')\n",
        "\n",
        "# Example usage\n",
        "runPrefixSum(256, 128, 1000000)\n",
        "runPrefixSum(512, 64, 1000000)\n",
        "runPrefixSum(1024, 32, 1000000)\n"
      ]
    }
  ]
}